import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import os

# ---------- å‚æ•°éƒ¨åˆ† ï¼ˆæ–°æ‰‹åªéœ€ä¿®æ”¹è¿™é‡Œï¼‰----------
search_query = "metformin and cancer cells"   # è¯·è¾“å…¥æœç´¢å…³é”®è¯
max_results = 10                              # è¯·è¾“å…¥æŠ“å–ç¯‡æ•°
save_path = r"E:\PHD WORK\PHD\Articles\metformin_methods_auto.csv" #è¯·è¾“å…¥è¾“å‡ºè·¯å¾„å’Œè¾“å‡ºæ–‡ä»¶åï¼ˆcsvæ ¼å¼ï¼‰
keywords = ['method', 'protocol', 'experimental', 'materials'] # Methods æ ‡é¢˜å…³é”®è¯ï¼ˆä¸€èˆ¬ä¸ç”¨æ”¹ï¼‰
# ç›®æ ‡æŠ“å–å…³é”®è¯ï¼ˆæ ¸å¿ƒå‚æ•°ï¼‰ï¼Œå¦‚éœ€å¤šä¸ªå…³é”®è¯ï¼Œç”¨|åˆ†éš”å¦‚éœ€å¤šä¸ªå…³é”®è¯ï¼Œè¯·ä½¿ç”¨æ­£åˆ™ORé€»è¾‘ï¼Œä¾‹å¦‚: r'\b(metformin|rapamycin|cisplatin)\b'ï¼›å¦‚éœ€åŒæ—¶åŒ¹é…å•å¤æ•°ï¼ˆå¦‚ cell / cellsï¼‰ï¼Œå¯åœ¨è¯å°¾åŠ ?
extract_targets = {
    "metformin": r"\bmetformin\b",
    "cells": r"\b(cells?|cell lines?)\b"
}
# ------------------------------

# è‡ªåŠ¨åˆ›å»ºä¿å­˜ç›®å½•
os.makedirs(os.path.dirname(save_path), exist_ok=True)

# ---------- Step 1ï¼šé€šè¿‡ Europe PMC æ£€ç´¢ PMC ID ----------
print(f"ğŸ” æ­£åœ¨æ£€ç´¢æ–‡çŒ®ï¼š{search_query}")

search_url = (
    f"https://www.ebi.ac.uk/europepmc/webservices/rest/search"
    f"?query={search_query}&resultType=core&format=json&pageSize={max_results}"
)
res = requests.get(search_url, timeout=20)
data = res.json()

pmc_ids = []
for hit in data.get("resultList", {}).get("result", []):
    if "pmcid" in hit:
        pmc_ids.append(hit["pmcid"])

if not pmc_ids:
    print("âš ï¸ æœªæ£€ç´¢åˆ°å¯ç”¨çš„ PMC æ–‡çŒ®ã€‚è¯·æ›´æ¢å…³é”®è¯ã€‚")
    exit()

print(f"âœ… å…±æ‰¾åˆ° {len(pmc_ids)} ç¯‡æ–‡çŒ®ï¼š{pmc_ids}")

# ---------- Step 2ï¼šæŠ“å–æ¯ç¯‡MethodsåŠç›®æ ‡æ®µè½ ----------
split_sent_regex = re.compile(r'(?<=[\.\?\!\;\n])\s+')
results = []

for pmc_id in pmc_ids:
    print(f"\n=== æ­£åœ¨å¤„ç† {pmc_id} ===")
    url = f"https://www.ebi.ac.uk/europepmc/webservices/rest/{pmc_id}/fullTextXML"

    try:
        res = requests.get(url, timeout=20)
        res.encoding = 'utf-8'


        def parse_xml_with_fallback(xml_text):
            #ä¼˜å…ˆä½¿ç”¨ lxml-xml è§£æ PMC XMLï¼Œè‹¥ä¸å¯ç”¨åˆ™è‡ªåŠ¨é€€å›åˆ° html.parserï¼ˆä¿è¯å¯è¿è¡Œï¼‰#
            try:
                return BeautifulSoup(xml_text, 'lxml-xml')
            except Exception:
                print("âš ï¸ æœªæ£€æµ‹åˆ° lxml-xmlï¼Œå°è¯•ä½¿ç”¨ html.parser è§£æï¼ˆå…¼å®¹æ¨¡å¼ï¼‰")
                return BeautifulSoup(xml_text, 'html.parser')

        soup = parse_xml_with_fallback(res.text)
        title_tag = soup.find('article-title')
        title = title_tag.get_text(strip=True) if title_tag else "No title"

        body = soup.find('body')

        # ä¸ºæ¯ä¸ªå…³é”®è¯å‡†å¤‡ä¸€ä¸ªç»“æœå®¹å™¨
        extracted_paragraphs = {k: [] for k in extract_targets}
        all_method_paragraphs = []

        if body:
            for sec in body.find_all('sec'):
                sec_title = sec.find('title')
                if sec_title and any(
                        k in sec_title.get_text(strip=True).lower() for k in keywords
                ):
                    for p in sec.find_all('p'):
                        text = p.get_text(" ", strip=True)
                        all_method_paragraphs.append(text)

                        # æ ¸å¿ƒï¼šè‡ªåŠ¨åŒ¹é…æ‰€æœ‰ç”¨æˆ·å®šä¹‰çš„å…³é”®è¯
                        for name, pattern in extract_targets.items():
                            if re.search(pattern, text, re.I):
                                extracted_paragraphs[name].append(text)

        # æ„å»ºè¾“å‡ºè¡Œ
        row = {
            "pmc_id": pmc_id,
            "title": title,
            "methods_text_full": " || ".join(all_method_paragraphs)
        }

        for name, paragraphs in extracted_paragraphs.items():
            row[f"methods_paragraphs_with_{name}"] = " || ".join(paragraphs)

        results.append(row)

        print(
            f"âœ… {pmc_id} å®Œæˆ | "
            + " | ".join(
                f"{k}: {len(v)}" for k, v in extracted_paragraphs.items()
            )
        )

        time.sleep(1)

    except Exception as e:
        print(f"âŒ {pmc_id} å‡ºé”™ï¼š{e}")
        results.append({
            "pmc_id": pmc_id,
            "title": "Error",
            "methods_text_full": ""
        })
# ---------- Step 3ï¼šå¯¼å‡º ----------
df = pd.DataFrame(results)
df.to_csv(save_path, index=False, encoding="utf-8-sig")
print(f"\nğŸ‰ æ‰¹é‡æŠ“å–å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°ï¼š{save_path}")
